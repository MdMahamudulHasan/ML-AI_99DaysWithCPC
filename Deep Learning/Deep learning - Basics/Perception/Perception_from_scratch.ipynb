{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SIL9F0iOQXIm"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sigmoid Perception Class**"
      ],
      "metadata": {
        "id": "S_N1m6kqRcqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class sigmoidPerception:\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        self.weights = np.random.randn(input_size)\n",
        "        self.bias = np.random.randn(1)\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.sigmoid(weighted_sum)\n",
        "\n",
        "    def fit(self, inputs, targets, learning_rate, num_epochs):\n",
        "        num_examples = inputs.shape[0]\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            for i in range(num_examples):\n",
        "                input_vector = inputs[i]\n",
        "                target = targets[i]\n",
        "\n",
        "                prediction = self.predict(input_vector)\n",
        "                error = target - prediction\n",
        "\n",
        "                # update weights\n",
        "                gradient_weights = error * prediction * (1 - prediction) * input_vector\n",
        "                self.weights += learning_rate * gradient_weights\n",
        "\n",
        "                # update bias\n",
        "                gradient_bias = error * prediction * (1 - prediction)\n",
        "                self.bias += learning_rate * gradient_bias\n",
        "\n",
        "    def evaluate(self, inputs, targets):\n",
        "        correct = 0\n",
        "\n",
        "        for input_vector, target in zip(inputs, targets):\n",
        "            prediction = self.predict(input_vector)\n",
        "\n",
        "            if prediction >= 0.5:\n",
        "                predicted_class = 1\n",
        "            else:\n",
        "                predicted_class = 0\n",
        "\n",
        "            if predicted_class == target:\n",
        "                correct += 1\n",
        "\n",
        "        accuracy = correct / len(inputs)  # accuracy = no of correct predictions / total number of data points\n",
        "        return accuracy\n"
      ],
      "metadata": {
        "id": "lB-vXrBtQoPV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [10, 20, 30]\n",
        "list2 = [0.2, 0.3, 0.4]\n",
        "\n",
        "for val1, val2 in zip(list1, list2):\n",
        "  print(val1, val2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWIsqtU2WvCX",
        "outputId": "b00d63ae-55ae-4b4b-d43f-3d8115da71d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 0.2\n",
            "20 0.3\n",
            "30 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class sigmoidPerception:\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        # Xavier Initialization for weights\n",
        "        self.weights = np.random.randn(input_size) / np.sqrt(input_size)\n",
        "        self.bias = np.random.randn(1)\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        # Sigmoid function with numerical stability\n",
        "        return np.where(z >= 0,\n",
        "                        1 / (1 + np.exp(-z)),\n",
        "                        np.exp(z) / (1 + np.exp(z)))\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.sigmoid(weighted_sum)\n",
        "\n",
        "    def fit(self, inputs, targets, learning_rate, num_epochs):\n",
        "        for epoch in range(num_epochs):\n",
        "            # Vectorized predictions\n",
        "            predictions = self.predict(inputs)\n",
        "            errors = targets - predictions\n",
        "\n",
        "            # Vectorized gradient computation\n",
        "            gradient_weights = np.dot(inputs.T, errors * predictions * (1 - predictions))\n",
        "            gradient_bias = np.sum(errors * predictions * (1 - predictions))\n",
        "\n",
        "            # Update weights and bias\n",
        "            self.weights += learning_rate * gradient_weights\n",
        "            self.bias += learning_rate * gradient_bias\n",
        "\n",
        "    def loss(self, predictions, targets):\n",
        "        # Binary cross-entropy loss with a small epsilon for numerical stability\n",
        "        epsilon = 1e-9\n",
        "        return -np.mean(targets * np.log(predictions + epsilon) + (1 - targets) * np.log(1 - predictions + epsilon))\n",
        "\n",
        "    def evaluate(self, inputs, targets):\n",
        "        correct = 0\n",
        "        for input_vector, target in zip(inputs, targets):\n",
        "            prediction = self.predict(input_vector)\n",
        "            predicted_class = 1 if prediction >= 0.5 else 0\n",
        "            if predicted_class == target:\n",
        "                correct += 1\n",
        "        accuracy = correct / len(inputs)  # accuracy = correct predictions / total number of data points\n",
        "        return accuracy\n"
      ],
      "metadata": {
        "id": "ZnQYcb2QW_TW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p1bwWc3hYXub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}